Args in experiment:
Namespace(random_seed=2024, is_training=1, model_id='test', model='VanillaRNN', data='Inpulse_hour', root_path='./data/ETT/', data_path='BCH_Inpulse_hour.csv', features='M', target='together', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, rnn_type='lstm', dec_way='pmf', seg_len=48, win_len=48, channel_id=1, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', pct_start=0.3, use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : test_VanillaRNN_Inpulse_hour_ftM_sl96_pl96_dm512_dr0.05_rtlstm_dwpmf_sl48_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4129
val 2065
test 2065
        iters: 100, epoch: 1 | loss: 0.3266756
        speed: 0.0947s/iter; left time: 357.0005s
Epoch: 1 cost time: 12.222424030303955
Epoch: 1, Steps: 129 | Train Loss: 0.2709090 Vali Loss: 0.2416366 Test Loss: 0.2484295
Validation loss decreased (inf --> 0.241637).  Saving model ...
Updating learning rate to 0.0001
        iters: 100, epoch: 2 | loss: 0.2423441
        speed: 0.1611s/iter; left time: 586.7962s
Epoch: 2 cost time: 11.893536806106567
Epoch: 2, Steps: 129 | Train Loss: 0.2210560 Vali Loss: 0.2139626 Test Loss: 0.2094462
Validation loss decreased (0.241637 --> 0.213963).  Saving model ...
Updating learning rate to 5e-05
        iters: 100, epoch: 3 | loss: 0.3013236
        speed: 0.1540s/iter; left time: 541.0124s
Epoch: 3 cost time: 10.90296983718872
Epoch: 3, Steps: 129 | Train Loss: 0.2174154 Vali Loss: 0.2118018 Test Loss: 0.2091159
Validation loss decreased (0.213963 --> 0.211802).  Saving model ...
Updating learning rate to 2.5e-05
        iters: 100, epoch: 4 | loss: 0.2454569
        speed: 0.1614s/iter; left time: 546.1627s
Epoch: 4 cost time: 11.943327903747559
Epoch: 4, Steps: 129 | Train Loss: 0.2172357 Vali Loss: 0.2129932 Test Loss: 0.2090024
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
        iters: 100, epoch: 5 | loss: 0.2907482
        speed: 0.1581s/iter; left time: 514.7117s
Epoch: 5 cost time: 11.828368425369263
Epoch: 5, Steps: 129 | Train Loss: 0.2170407 Vali Loss: 0.2122432 Test Loss: 0.2088521
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
        iters: 100, epoch: 6 | loss: 0.1823068
        speed: 0.1573s/iter; left time: 491.6915s
Epoch: 6 cost time: 11.691401720046997
Epoch: 6, Steps: 129 | Train Loss: 0.2167148 Vali Loss: 0.2125303 Test Loss: 0.2086217
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : test_VanillaRNN_Inpulse_hour_ftM_sl96_pl96_dm512_dr0.05_rtlstm_dwpmf_sl48_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2065
mse:0.7938477993011475, mae:0.2091159075498581, ms/sample:1.3450846545055473