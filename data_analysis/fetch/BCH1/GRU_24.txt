Args in experiment:
Namespace(random_seed=2024, is_training=1, model_id='test', model='VanillaRNN', data='Inpulse_hour', root_path='./data/ETT/', data_path='BCH_Inpulse_hour.csv', features='M', target='together', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=24, rnn_type='gru', dec_way='pmf', seg_len=48, win_len=48, channel_id=1, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=30, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', pct_start=0.3, use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : test_VanillaRNN_Inpulse_hour_ftM_sl96_pl24_dm512_dr0.05_rtgru_dwpmf_sl48_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4201
val 2137
test 2137
        iters: 100, epoch: 1 | loss: 0.2039199
        speed: 0.0304s/iter; left time: 116.3757s
Epoch: 1 cost time: 4.007500171661377
Epoch: 1, Steps: 131 | Train Loss: 0.2901295 Vali Loss: 0.2477299 Test Loss: 0.2569846
Validation loss decreased (inf --> 0.247730).  Saving model ...
Updating learning rate to 0.0001
        iters: 100, epoch: 2 | loss: 0.3377258
        speed: 0.0496s/iter; left time: 183.5145s
Epoch: 2 cost time: 3.5867834091186523
Epoch: 2, Steps: 131 | Train Loss: 0.2253468 Vali Loss: 0.2068815 Test Loss: 0.2046315
Validation loss decreased (0.247730 --> 0.206881).  Saving model ...
Updating learning rate to 5e-05
        iters: 100, epoch: 3 | loss: 0.1694705
        speed: 0.0499s/iter; left time: 178.0913s
Epoch: 3 cost time: 3.6924784183502197
Epoch: 3, Steps: 131 | Train Loss: 0.2013599 Vali Loss: 0.1828357 Test Loss: 0.1844999
Validation loss decreased (0.206881 --> 0.182836).  Saving model ...
Updating learning rate to 2.5e-05
        iters: 100, epoch: 4 | loss: 0.1337489
        speed: 0.0485s/iter; left time: 166.8733s
Epoch: 4 cost time: 3.6200919151306152
Epoch: 4, Steps: 131 | Train Loss: 0.1926729 Vali Loss: 0.1857788 Test Loss: 0.1842675
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
        iters: 100, epoch: 5 | loss: 0.1520242
        speed: 0.0467s/iter; left time: 154.3492s
Epoch: 5 cost time: 3.485893487930298
Epoch: 5, Steps: 131 | Train Loss: 0.1903945 Vali Loss: 0.1845296 Test Loss: 0.1836170
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
        iters: 100, epoch: 6 | loss: 0.1144563
        speed: 0.0484s/iter; left time: 153.7491s
Epoch: 6 cost time: 3.4875400066375732
Epoch: 6, Steps: 131 | Train Loss: 0.1910244 Vali Loss: 0.1837567 Test Loss: 0.1834856
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : test_VanillaRNN_Inpulse_hour_ftM_sl96_pl24_dm512_dr0.05_rtgru_dwpmf_sl48_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2137
mse:0.679889976978302, mae:0.18449987471103668, ms/sample:0.712641835156924